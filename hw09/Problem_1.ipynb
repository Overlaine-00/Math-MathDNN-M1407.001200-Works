{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Import necessary modules and set parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c674b2e30b634ec595b1b4ab33f76827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079d68174fda40cf85c90d54586bead6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7b71e37a0a4cd18f7cc18015c66660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47da8f33bfb6476b8b0b07d5bf444e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to ./kmnist_data/KMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62182a725122406bad04acad0f015c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18165135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./kmnist_data/KMNIST\\raw\\train-images-idx3-ubyte.gz to ./kmnist_data/KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to ./kmnist_data/KMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4304351fd5449bfa7a94242ef5b1992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./kmnist_data/KMNIST\\raw\\train-labels-idx1-ubyte.gz to ./kmnist_data/KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to ./kmnist_data/KMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ad178f50c494596624a761c30ca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3041136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./kmnist_data/KMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./kmnist_data/KMNIST\\raw\n",
      "\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to ./kmnist_data/KMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cab5f59b08f49d681b833eca36a3c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./kmnist_data/KMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./kmnist_data/KMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# KMNIST dataset, only need test dataset\n",
    "anomaly_dataset = datasets.KMNIST(root='./kmnist_data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Define encoders and decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        z = F.relu(self.fc3(x))\n",
    "        return z\n",
    "\n",
    "# Define Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 784)\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        x = F.sigmoid(self.fc3(z))  # to make output's pixels are 0~1\n",
    "        x = x.view(x.size(0), 1, 28, 28) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "define loss and optimizer, and designate encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Train data. Results are displayed in below figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th epoch starting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cjhy29\\Anaconda3\\envs\\RL\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th epoch starting.ing batch #499 reconstruction loss: 0.031978\n",
      "2th epoch starting.ing batch #499 reconstruction loss: 0.022704\n",
      "3th epoch starting.ing batch #499 reconstruction loss: 0.018204\n",
      "4th epoch starting.ing batch #499 reconstruction loss: 0.017231\n",
      "5th epoch starting.ing batch #499 reconstruction loss: 0.015098\n",
      "6th epoch starting.ing batch #499 reconstruction loss: 0.013482\n",
      "7th epoch starting.ing batch #499 reconstruction loss: 0.013510\n",
      "8th epoch starting.ing batch #499 reconstruction loss: 0.011371\n",
      "9th epoch starting.ing batch #499 reconstruction loss: 0.011654\n",
      "Time ellapsed in training is: 77.39564347267151n loss: 0.011139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(epochs) :\n",
    "    print(\"{}th epoch starting.\".format(epoch))\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    for batch, (images, _) in enumerate(train_loader) :\n",
    "        images = images.to(device)\n",
    "        z = enc(images)\n",
    "        reconstructed_images = dec(z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss = loss_function(images, reconstructed_images)\n",
    "        train_loss.backward()\n",
    "        train_loss_list.append(train_loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch:3d}] Processing batch #{batch:3d} reconstruction loss: {train_loss.item():.6f}\", end='\\r')\n",
    "end = time.time()\n",
    "print(\"Time ellapsed in training is: {}\".format(end - start))\n",
    "\n",
    "# plotting train loss\n",
    "plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'r', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')\n",
    "\n",
    "enc.eval()\n",
    "dec.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Make use of validation set to set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.00015767693192594964\n"
     ]
    }
   ],
   "source": [
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)\n",
    "\n",
    "validation_loss_list = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in validation_loader:\n",
    "        images = images.to(device)\n",
    "        z = enc(images)\n",
    "        reconstructed_images = dec(z)\n",
    "        reconstructed_images = reconstructed_images\n",
    "\n",
    "        validation_loss_list.append(nn.MSELoss()(images, reconstructed_images).to('cpu').item())    # dim = 0\n",
    "    validation_loss_list = np.array(validation_loss_list)**2\n",
    "\n",
    "mean, std = np.mean(validation_loss_list), np.std(validation_loss_list)\n",
    "\n",
    "threshold = mean + 3 * std\n",
    "print(\"threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Now we evaluate our network. Type 1 error occurs when our network recovers original data not neatly, i.e., when loss exceeds threshold.  \n",
    "The result is almost closed to usual p-value 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of MNIST test set:  100, number of MNIST anomalies:  5   =>  type 1 error =  0.05\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loss_list = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        z = enc(images)\n",
    "        reconstructed_images = dec(z)\n",
    "        reconstructed_images = reconstructed_images\n",
    "\n",
    "        test_loss_list.append(nn.MSELoss()(images, reconstructed_images).to('cpu').item())    # dim = 0\n",
    "    test_loss_list = np.array(test_loss_list)**2\n",
    "\n",
    "print(\"total number of MNIST test set: \", len(test_loss_list), end=\", \")\n",
    "anomalies = test_loss_list[test_loss_list > threshold]\n",
    "print(\"number of MNIST anomalies: \", len(anomalies), \"  =>  type 1 error = \", len(anomalies)/len(test_loss_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "We also take test for KMNIST data. The result is almost same (actually same, since ...044 happens because of floating point).  \n",
    "This means, our auto-encoder works well for KMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of KMNIST test set:  100, number of KMNIST non-anomalies:  95   =>  type 2 error =  0.050000000000000044\n"
     ]
    }
   ],
   "source": [
    "anomaly_loader = torch.utils.data.DataLoader(dataset=anomaly_dataset, batch_size=batch_size)\n",
    "\n",
    "test_loss_list_2 = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        z = enc(images)\n",
    "        reconstructed_images = dec(z)\n",
    "        reconstructed_images = reconstructed_images\n",
    "\n",
    "        test_loss_list_2.append(nn.MSELoss()(images, reconstructed_images).to('cpu').item())    # dim = 0\n",
    "    test_loss_list_2 = np.array(test_loss_list_2)**2\n",
    "\n",
    "print(\"total number of KMNIST test set: \", len(test_loss_list), end=\", \")\n",
    "non_anomalies = test_loss_list[test_loss_list < threshold]\n",
    "print(\"number of KMNIST non-anomalies: \", len(non_anomalies), \"  =>  type 2 error = \", 1 - len(non_anomalies)/len(test_loss_list_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b317da953ad838286c0c6ab0dfc4969c0da5f5eb296aba9f813b609fe07b4eeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
